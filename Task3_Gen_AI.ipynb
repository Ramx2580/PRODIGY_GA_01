{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt7m+4yWLSjXYtRxjEXXfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramx2580/Prodigy-InfoTech-Gen-AI/blob/main/Task3_Gen_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbPnoJJi2xld"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n",
        "\n",
        "import torch\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "jxJ4WodV38Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(mode=\"RGB\")\n",
        "\n",
        "    pixel_values = feature_extractor(images=[image], return_tensors=\"pt\").pixel_values.to(device)\n",
        "\n",
        "    output_ids = model.generate(pixel_values, max_length=16, num_beams=4)\n",
        "    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Generated Caption\")\n",
        "    plt.show()\n",
        "\n",
        "    return caption"
      ],
      "metadata": {
        "id": "YNt_xzc74aeO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From URL\n",
        "image_url = \"https://images.unsplash.com/photo-1593642634367-d91a135587b5\"\n",
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "image.save(\"sample.jpg\")  # Save locally to caption\n",
        "caption = generate_caption(\"sample.jpg\")\n",
        "print(\"Generated Caption:\", caption)"
      ],
      "metadata": {
        "id": "SUHL19Gl4s5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}